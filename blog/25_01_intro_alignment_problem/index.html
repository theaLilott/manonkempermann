<!DOCTYPE html>
<html lang="en-gb"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="content-type" content="text/html">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title itemprop="name">Alignment or why we need to think about AI safety | Manon Kempermann</title>
<meta property="og:title" content="Alignment or why we need to think about AI safety | Manon Kempermann" />
<meta name="twitter:title" content="Alignment or why we need to think about AI safety | Manon Kempermann" />
<meta itemprop="name" content="Alignment or why we need to think about AI safety | Manon Kempermann" />
<meta name="application-name" content="Alignment or why we need to think about AI safety | Manon Kempermann" />
<meta property="og:site_name" content="Manon Kempermann" />

<meta name="description" content="Here I write about my journey into AI safety">
<meta itemprop="description" content="Here I write about my journey into AI safety" />
<meta property="og:description" content="Here I write about my journey into AI safety" />
<meta name="twitter:description" content="Here I write about my journey into AI safety" />

<meta property="og:locale" content="en-gb" />
<meta name="language" content="en-gb" />

  <link rel="alternate" hreflang="en-gb" href="http://localhost:1313/blog/25_01_intro_alignment_problem/" title="English" />





    
    
    

    <meta property="og:type" content="article" />
    <meta property="og:article:published_time" content=2025-01-02T10:23:21&#43;0100 />
    <meta property="article:published_time" content=2025-01-02T10:23:21&#43;0100 />
    <meta property="og:url" content="http://localhost:1313/blog/25_01_intro_alignment_problem/" />

    
    <meta property="og:article:author" content="Manon Kempermann" />
    <meta property="article:author" content="Manon Kempermann" />
    <meta name="author" content="Manon Kempermann" />
    
    

    

    <script defer type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "Article",
        "headline": "Alignment or why we need to think about AI safety",
        "author": {
        "@type": "Person",
        "name": ""
        },
        "datePublished": "2025-01-02",
        "description": "",
        "wordCount":  729 ,
        "mainEntityOfPage": "True",
        "dateModified": "2025-01-02",
        "image": {
        "@type": "imageObject",
        "url": ""
        },
        "publisher": {
        "@type": "Organization",
        "name": "Manon Kempermann"
        }
    }
    </script>


<meta name="generator" content="Hugo 0.140.1">

    
    <meta property="og:url" content="http://localhost:1313/blog/25_01_intro_alignment_problem/">
  <meta property="og:site_name" content="Manon Kempermann">
  <meta property="og:title" content="Alignment or why we need to think about AI safety">
  <meta property="og:description" content="I want to begin this blog with an outline of the problem with AI and why we need to pay attention to AI safety.
Recently, I caught up with a friend who countered my interest in AI safety by claiming that this focus was “so German”—always overly cautious, regulating everything too much, and thereby slowing down innovation and blocking AI’s potential. While his argument has some merit, I believe there’s a deeper dimension to how AI could go wrong—one that goes beyond misuse, which was essentially his concern. This dimension is referred to as the alignment problem, and it’s what we’ll explore today.">
  <meta property="og:locale" content="en_gb">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blog">
    <meta property="article:published_time" content="2025-01-02T10:23:21+01:00">
    <meta property="article:modified_time" content="2025-01-02T10:23:21+01:00">


    
    
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Alignment or why we need to think about AI safety">
  <meta name="twitter:description" content="I want to begin this blog with an outline of the problem with AI and why we need to pay attention to AI safety.
Recently, I caught up with a friend who countered my interest in AI safety by claiming that this focus was “so German”—always overly cautious, regulating everything too much, and thereby slowing down innovation and blocking AI’s potential. While his argument has some merit, I believe there’s a deeper dimension to how AI could go wrong—one that goes beyond misuse, which was essentially his concern. This dimension is referred to as the alignment problem, and it’s what we’ll explore today.">


    

    <link rel="canonical" href="http://localhost:1313/blog/25_01_intro_alignment_problem/">
    <link href="/style.min.9fefd2c6b79ba2d16ca8755a6defbed0d3724a14ad11a23011c537ec22744419.css" rel="stylesheet">
    <link href="/code-highlight.min.706d31975fec544a864cb7f0d847a73ea55ca1df91bf495fd12a177138d807cf.css" rel="stylesheet">

    
    <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png">
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg">
    <link rel="shortcut icon" href="/favicon.ico">




<link rel="manifest" href="http://localhost:1313/site.webmanifest">

<meta name="msapplication-config" content="/browserconfig.xml">
<meta name="msapplication-TileColor" content="#2d89ef">
<meta name="theme-color" content="#434648">

    
    <link rel="icon" type="image/svg+xml" href="/icons/favicon.svg">

    
    
</head>
<body data-theme = "auto" class="notransition">

<script src="/js/theme.js"></script>

<div class="navbar" role="navigation">
    <nav class="menu" aria-label="Main Navigation">
        <a href="/" class="logo">
            <svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" 
viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" 
stroke-linejoin="round" class="feather feather-home">
<title>Home</title>
<path d="M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path>
<polyline points="9 22 9 12 15 12 15 22"></polyline>
</svg>
        </a>
        <input type="checkbox" id="menu-trigger" class="menu-trigger" />
        <label for="menu-trigger">
            <span class="menu-icon">
                <svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" stroke="currentColor" fill="none" viewBox="0 0 14 14"><title>Menu</title><path stroke-linecap="round" stroke-linejoin="round" d="M10.595 7L3.40726 7"></path><path stroke-linecap="round" stroke-linejoin="round" d="M10.5096 3.51488L3.49301 3.51488"></path><path stroke-linecap="round" stroke-linejoin="round" d="M10.5096 10.4851H3.49301"></path><path stroke-linecap="round" stroke-linejoin="round" d="M0.5 12.5V1.5C0.5 0.947715 0.947715 0.5 1.5 0.5H12.5C13.0523 0.5 13.5 0.947715 13.5 1.5V12.5C13.5 13.0523 13.0523 13.5 12.5 13.5H1.5C0.947715 13.5 0.5 13.0523 0.5 12.5Z"></path></svg>
            </span>
        </label>

        <div class="trigger">
            <ul class="trigger-container">
                
                
                <li>
                    <a class="menu-link " href="/">
                        Home
                    </a>
                    
                </li>
                
                <li>
                    <a class="menu-link active" href="/blog/">
                        Blog
                    </a>
                    
                </li>
                
                <li>
                    <a class="menu-link " href="/page/cv/">
                        CV
                    </a>
                    
                </li>
                
                <li class="menu-separator">
                    <span>|</span>
                </li>
                
                
            </ul>
            <a id="mode" href="#">
                <svg xmlns="http://www.w3.org/2000/svg" class="mode-sunny" width="21" height="21" viewBox="0 0 14 14" stroke-width="1">
<title>LIGHT</title><g><circle cx="7" cy="7" r="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></circle><line x1="7" y1="0.5" x2="7" y2="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="2.4" x2="3.82" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="0.5" y1="7" x2="2.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="11.6" x2="3.82" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="7" y1="13.5" x2="7" y2="11.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="11.6" x2="10.18" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="13.5" y1="7" x2="11.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="2.4" x2="10.18" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line></g></svg>
                <svg xmlns="http://www.w3.org/2000/svg" class="mode-moon" width="21" height="21" viewBox="0 0 14 14" stroke-width="1">
<title>DARK</title><g><circle cx="7" cy="7" r="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></circle><line x1="7" y1="0.5" x2="7" y2="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="2.4" x2="3.82" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="0.5" y1="7" x2="2.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="11.6" x2="3.82" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="7" y1="13.5" x2="7" y2="11.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="11.6" x2="10.18" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="13.5" y1="7" x2="11.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="2.4" x2="10.18" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line></g></svg>
            </a>
        </div>
    </nav>
</div>

<div class="wrapper post">
    <main class="page-content" aria-label="Content">
        <article>
            <header class="header">
                <h1 class="header-title">Alignment or why we need to think about AI safety</h1>
                
                
                
                <div class="post-meta">
                    <time datetime="2025-01-02T10:23:21&#43;01:00" itemprop="datePublished"> 2 Jan 2025 </time>
                </div>
                
            </header>
            
            <div class="page-content">
                <p>I want to begin this blog with an outline of the problem with AI and why we need to pay attention to AI safety.</p>
<p>Recently, I caught up with a friend who countered my interest in AI safety by claiming that this focus was “so German”—always overly cautious, regulating everything too much, and thereby slowing down innovation and blocking AI’s potential. While his argument has some merit, I believe there’s a deeper dimension to how AI could go wrong—one that goes beyond misuse, which was essentially his concern. This dimension is referred to as the alignment problem, and it’s what we’ll explore today.</p>
<h3 id="machines-these-days">Machines these days</h3>
<p>Let’s start with a simple example: an old-fashioned machine like a cash machine. Cash machines today often have digital displays, but their behavior is fairly straightforward. The machine reads the user’s card, asks for a PIN and the desired withdrawal amount, and then dispenses cash. Of course, there are additional steps involved, and errors can occur, but the machine’s behavior is generally unambiguous. If it’s programmed correctly, it will always do what we expect—dispense the correct amount of cash. If it makes a mistake, the problem lies in the program, and we can fix it by correcting the code.</p>
<p>Now, consider a different kind of machine: the spam detector in your email inbox. What do you expect it to do? It should distinguish between spam and non-spam emails. But how does it decide what is spam? The detector has to learn this distinction.</p>
<p>We train the spam detector by providing examples of emails that are spam and others that are not. Without going into technical details, you can imagine how you might judge an email as spam—certain features like generic greetings (“Dear User…”) or offers to buy something might signal spam. The detector learns these features and uses them to classify new emails.</p>
<p>But as you’ve probably experienced, the spam detector isn’t perfect. Sometimes, it flags an important email as spam—a mistake. This happens because the detector didn’t learn correctly how to distinguish between spam and non-spam emails. Unlike the cash machine, where you can fix the problem by changing a line of code, the spam detector’s behavior depends on what it learned from the examples.</p>
<h3 id="when-the-behavior-gets-more-complex">When the behavior gets more complex</h3>
<p>As we have seen with the spam detector, when machines learn behavior, there is always the risk that they will learn something different from what we intended. This misalignment becomes even more challenging when the desired behavior involves human values or norms. How do you teach a machine values when humans themselves struggle to define and agree on them?</p>
<p>This is the essence of the alignment problem. You might think, “If my spam detector gets it wrong, it’s annoying but not a big deal.” But the stakes are much higher with advanced AI systems.</p>
<p>Take ChatGPT, for example. It also learns behavior—in this case, generating text based on your messages. But unlike the spam detector, its behavior is even less defined. You could ask it a factual question with a clear answer, or you could ask for advice, where the response depends heavily on <em>your</em> values or norms the model might not fully understand.</p>
<p>Now imagine AI systems far more capable than ChatGPT, even surpassing human intelligence in certain areas. If such systems are not aligned with human values, they could pursue goals in ways that harm us, even unintentionally. For instance, an AI system tasked with solving a global problem might take actions we didn’t foresee, causing more harm than good.</p>
<h3 id="why-alignment-matters">Why alignment matters</h3>
<p>As we’ve seen, machines that learn behavior can become misaligned to what we expect them to do. The challenge is that this behavior often relies on human values, which are notoriously difficult to teach a machine. The alignment problem lies at the heart of AI safety research because misaligned AI could lead to unintended and potentially harmful outcomes.</p>
<p>While a misclassified email is a small annoyance, misaligned AI systems operating in high-stakes areas like healthcare, justice, or governance could have far-reaching consequences.</p>
<p>In the following posts, we will dive deeper into the risks of misaligned AI and examine how realistic these risks are. For now, it is enough to understand that AI safety isn’t only about preventing misuse. It’s about ensuring that AI does what we want it to do, in particular not causing (unintentional) harm.</p>

            </div>
        </article></main>
</div>
<footer class="footer">
    <span class="footer_item"> </span>
    &nbsp;

    <div class="footer_social-icons">
<a href="https://github.com/theaLilott" target="_blank" rel="noopener noreferrer me"
    title="Github">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path
        d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22">
    </path>
</svg>
</a>
<a href="https://www.linkedin.com/in/manon-kempermann-0a8396263/" target="_blank" rel="noopener noreferrer me"
    title="Linkedin">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path>
    <rect x="2" y="9" width="4" height="12"></rect>
    <circle cx="4" cy="4" r="2"></circle>
</svg>
</a>
</div>
    <small class="footer_copyright">
        © 2025 Manon Kempermann.
        Powered by <a href="https://github.com/hugo-sid/hugo-blog-awesome" target="_blank" rel="noopener">Hugo blog awesome</a>.
    </small>
</footer><a href="#" title="Go to top" id="totop">
    <svg xmlns="http://www.w3.org/2000/svg" width="48" height="48" fill="currentColor" stroke="currentColor" viewBox="0 96 960 960">
    <path d="M283 704.739 234.261 656 480 410.261 725.739 656 677 704.739l-197-197-197 197Z"/>
</svg>

</a>


    




    
    
        
    

    
    
        
    



    
    <script async src="http://localhost:1313/js/main.js" ></script>

    

</body>
</html>
